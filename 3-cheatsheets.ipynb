{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c75ec317",
   "metadata": {},
   "source": [
    "# Unit 3: Infinite Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b5a16",
   "metadata": {},
   "source": [
    "## Direct comparison test\n",
    "\n",
    "### Let $0<a_n<b_n$ for all $n\\geq N$\n",
    "### Then\n",
    "### - If $\\displaystyle \\sum_{n=N}^{\\infty} b_n$ converges, then $\\displaystyle \\sum_{n=N}^{\\infty} a_n$ also converges\n",
    "### - If $\\displaystyle \\sum_{n=N}^{\\infty} a_n$ diverges, then $\\displaystyle \\sum_{n=N}^{\\infty} b_n$ also diverges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09169b0c",
   "metadata": {},
   "source": [
    "## Limit comparison\n",
    "\n",
    "### If\n",
    "### 1. $\\displaystyle \\frac{f(n)}{g(n)} \\to c$ where $c\\neq 0$ is finite,\n",
    "### 2. $g(n)>0$ for all $n>N$ for some $N>0$,\n",
    "### then $\\displaystyle \\sum_{n=1}^{\\infty} f(n)$ and $\\displaystyle \\sum_{n=1}^{\\infty} g(n)$ either ***both converge or both diverge***.\n",
    "### In other words, if $f(n)$ and $g(n)$ decay at the same rate as $n$ tends to $\\infty$ then the series $\\displaystyle \\sum_{n=1}^{\\infty} f(n)$ and $\\displaystyle \\sum_{n=1}^{\\infty} g(n)$ converge or diverge together.\n",
    "### This is analogous to limit comparison for improper integrals.\n",
    "### ***Note***: The condition $\\displaystyle \\frac{f(n)}{g(n)} \\to c\\neq 0$ as $n\\to \\infty$ is equivalent to\n",
    "## $$ f(n) \\sim c g(n), \\quad \\text{that is}, \\quad \\frac{f(n)}{c g(n)} \\to 1, \\, \\text{as}\\,n\\to\\infty $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5784ea",
   "metadata": {},
   "source": [
    "## More on limit comparison\n",
    "\n",
    "### We can also use limit comparison in the following way.\n",
    "### Suppose $f(n), g(n) > 0$ for all $n\\geq N$ for some large $N$.\n",
    "### If $\\displaystyle \\frac{f(n)}{g(n)} \\to 0$ as $n \\to \\infty$ that is, $f(n)$ decays faster than $g(n)$ then\n",
    "### - $\\displaystyle \\sum_{n=N}^{\\infty} g(n)$ converges implies $\\displaystyle \\sum_{n=N}^{\\infty} f(n)$ converges;\n",
    "### - $\\displaystyle \\sum_{n=N}^{\\infty} f(n)$ diverges implies $\\displaystyle \\sum_{n=N}^{\\infty} g(n)$ diverges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd59a3d",
   "metadata": {},
   "source": [
    "### ***Example***\n",
    "### Determine is the following series converges or diverges.\n",
    "## $$ \\sum_{n=10}^{\\infty} \\frac{\\cos^2(n^3+n^2+1)}{n\\sqrt{n-2}} $$\n",
    "\n",
    "### ***Solution***\n",
    "### We start with direct comparison:\n",
    "## $$ \\begin{array} {rcl} \\, &  & \\displaystyle \\frac{\\cos^2(n^3+n^2+1)}{n\\sqrt{n-2}} \\leq \\frac{1}{n\\sqrt{n-2}}\\, \\text{for all}\\,n \\\\ \\implies & & \\displaystyle \\sum_{n=10}^{\\infty} \\frac{\\cos^2(n^3+n^2+1)}{n\\sqrt{n-2}} \\leq \\sum_{n=10}^{\\infty} \\frac{1}{n\\sqrt{n-2}} \\end{array} $$\n",
    "### Next, we use limit comparison to show $\\displaystyle \\sum_{n=10}^{\\infty} \\frac{1}{n\\sqrt{n-2}}$ converges. Since\n",
    "## $$ \\frac{1/(n\\sqrt{n-2})}{1/n^{3/2}} \\to 1\\quad (\\text{as}\\,n\\to \\infty) $$\n",
    "### and $\\displaystyle \\sum_{n=10}^{\\infty} \\frac{1}{n^{3/2}}$ converges, $\\displaystyle \\sum_{n=10}^{\\infty} \\frac{1}{n\\sqrt{n-2}}$ also converges.\n",
    "\n",
    "### The two results together imply the given series converges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e49707",
   "metadata": {},
   "source": [
    "## Ratio test\n",
    "\n",
    "### The ***ratio test*** is another way to determine convergence of a series.\n",
    "### Consider $\\displaystyle \\sum_{n=1}^{\\infty} a_n$ where $a_n > 0$ for all $n>N$.\n",
    "### Define\n",
    "## $$ L = \\lim_{n\\to\\infty}\\frac{a_{n+1}}{a_n} $$\n",
    "### There are three cases:\n",
    "### - If $L<1$ then the series ***converges***;\n",
    "### - If $L>1$ then the series ***diverges***;\n",
    "### - If $L=1$ then there is ***no conclusion***, i.e. the series can diverge or converge.\n",
    "### Here, we focus on series $\\displaystyle \\sum_{n=1}^{\\infty} a_n$ where $a_n>0$ for all $n$ large. You will see shortly that you can use the ratio test on series whose tail is not always positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac2e589",
   "metadata": {},
   "source": [
    "## Root tests\n",
    "\n",
    "### The ***root test*** is yet another test to determine the convergence of a series.\n",
    "### Consider $\\displaystyle \\sum_{n=1}^{\\infty}$ where $a_n>0$ for all $n>N$.\n",
    "### Define\n",
    "## $$ L = \\lim_{n\\to\\infty} \\sqrt[n]{a_n} = \\lim_{n\\to\\infty} (a_n)^{\\frac{1}{n}} $$\n",
    "### The conclusions are the same as for the ratio test, that is,\n",
    "### - If $L<1$ then the series ***converges***;\n",
    "### - If $L>1$ then the series ***diverges***;\n",
    "### - If $L=1$ then there is ***no conclusion***, that is, the series can either diverge or converge.\n",
    "### The root test can also be used for series whose tail consist of negative terms. You will see this shortly.\n",
    "### We are not going to discuss the proof of the root test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76491a0",
   "metadata": {},
   "source": [
    "## A more difficult limit\n",
    "\n",
    "### When using the root test, you may also encounter $\\displaystyle \\lim_{n\\to\\infty} (n!)^{\\frac{1}{n}}$ This limit is harder to evaluate. \n",
    "### In fact,\n",
    "## $$ \\lim_{n\\to\\infty} (n!)^{\\frac{1}{n}} = \\infty $$\n",
    "### ***Computation of the limit***\n",
    "### We will first compute $\\displaystyle \\ln$ of the limit and then exponentiate.\n",
    "## $$ \\begin{array} {rcl} \\displaystyle \\ln(\\lim_{n\\to\\infty} (n!)^{\\frac{1}{n}}) & = & \\displaystyle \\lim_{n\\to\\infty} \\frac{\\ln(n!)}{n} \\\\ \\, & = & \\displaystyle \\lim_{n\\to\\infty} \\frac{\\displaystyle \\sum_{k=2}^{n}\\ln(k)}{n} \\end{array} $$\n",
    "### To show the limit is infinite, we can compare $\\displaystyle \\frac{\\displaystyle \\sum_{k=2}^{n}\\ln(k)}{n}$ with a smaller function whose limit is infinite. Let us proceed.\n",
    "### The partial sum $\\displaystyle \\sum_{k=2}^{n}\\ln(k) $ is the right Riemann sum of $\\displaystyle \\int_{1}^{n}\\ln(x)dx$ with $\\Delta x = 1$ Since $\\ln(x)$ is an increasing function,\n",
    "## $$ \\sum_{k=2}^{n}\\ln(k) > \\int_{1}^{n}\\ln(x)dx $$\n",
    "### Now, we evaluate the integral using integration by parts:\n",
    "## $$ \\begin{array} {rcl} \\displaystyle \\int \\ln(x) dx & = & \\displaystyle x\\ln(x) - \\int \\frac{x}{x}dx \\quad (u=\\ln(x), dv=dx) \\\\ \\, & = & \\displaystyle x\\ln(x) - x \\\\ \\displaystyle \\implies \\int_{1}^{n}\\ln(x)dx & = & \\displaystyle n\\ln(n)-n+1 \\end{array}  $$\n",
    "### Therefore, we have a lower bound for $\\displaystyle \\sum_{k=1}^{n}\\ln(k)$:\n",
    "## $$ \\sum_{k=1}^{n}\\ln(k) > n\\ln(n)-n+1 $$\n",
    "### Let us get back to evaluating the limit.\n",
    "## $$ \\begin{array} {rcl} \\displaystyle \\ln(\\lim_{n\\to\\infty} (n!)^{\\frac{1}{n}}) & = & \\displaystyle \\lim_{n\\to\\infty} \\frac{\\displaystyle \\sum_{k=2}^{n} \\ln(k)}{n} \\\\ \\, & > & \\displaystyle \\lim_{n\\to\\infty} (\\ln(n)-1+\\frac{1}{n}) \\\\ \\, & = & \\infty \\end{array} $$\n",
    "### This implies\n",
    "## $$ \\lim_{n\\to\\infty} (n!)^{\\frac{1}{n}} = e^{\\infty} = \\infty $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c305ab",
   "metadata": {},
   "source": [
    "## Root test continued\n",
    "\n",
    "### ***Worked examples: root test***\n",
    "\n",
    "### ***Example 1***: the geometric series\n",
    "### The root test is another way to determine convergence of a geometric series. Consider\n",
    "## $$ \\sum_{n=1}^{\\infty} x^n\\quad\\text{where}\\,x>0 $$\n",
    "### To use the root test, we first compute $L$.\n",
    "## $$ \\begin{array} {rcl} L & = & \\displaystyle \\lim_{n\\to\\infty} \\sqrt[n]{x^n} \\\\ \\, & = & \\displaystyle \\lim_{n\\to\\infty} x \\\\ \\, & = & x \\quad (x>0) \\end{array} $$\n",
    "### Therefore, the root test tells us that $\\displaystyle \\sum_{n=1}^{\\infty} x^n \\quad (x>0) $ converges when $L=x<1$, and diverges when $L=x>1$. The root test does not give any information when $L=x=1$ even though we already know by the divergence test that $\\displaystyle \\sum_{n=1}^{\\infty} 1^n$ diverges.\n",
    "\n",
    "### ***Example 2***\n",
    "### We will use the root test to determine if the following series converges or diverges.\n",
    "## $$ \\sum_{n=1}^{\\infty} \\frac{n^2}{2^n} $$\n",
    "### First, we compute $\\displaystyle L = \\lim_{n\\to\\infty} (a_n)^{\\frac{1}{n}}$.\n",
    "## $$ \\begin{array} {rcl} L & = & \\displaystyle \\lim_{n\\to\\infty} (\\frac{n^2}{2^n})^{\\frac{1}{n}} \\\\ \\, & = & \\displaystyle \\lim_{n\\to\\infty} \\frac{(n^2)^{\\frac{1}{n}}}{2} \\\\ \\, & = & \\displaystyle \\frac{1}{2}\\lim_{n\\to\\infty} (n^2)^{\\frac{1}{n}} \\\\ \\, & = & \\displaystyle \\frac{1}{2} \\quad (\\lim_{n\\to\\infty} (n^2)^{\\frac{1}{n}}=1\\,\\text{from previous page}) \\end{array} $$\n",
    "### Therefore, since $L<1$ we conclude from the root test that the series $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{n^2}{2^n}$ converges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5290345",
   "metadata": {},
   "source": [
    "## Conditional Convergence\n",
    "\n",
    "### ***Absolute convergence versus conditional convergence***\n",
    "\n",
    "### So far, we have focused on series whose terms are positive (with the exception of the geometric series and the divergence test). For general series, including series with both positive and negative terms, there are two notions of convergence.\n",
    "\n",
    "### Consider the series\n",
    "## $$ S = \\sum_{n=1}^{\\infty} a_n \\quad (a_n\\, \\text{can be positive or negative}) $$\n",
    "### The series $S$ is ***absolutely convergent*** if $\\displaystyle \\sum_{n=1}^{\\infty} |a_n| $ converges.\n",
    "### The series $S$ is ***conditionally convergent*** if it converges but is ***not absolutely convergent***.\n",
    "### Strange to say, an absolute convergent series is ***not*** conditionally convergent.\n",
    "### For series with only positive terms, absolute convergence is the same as convergence.\n",
    "### In general, absolute convergence of a series implies convergence.\n",
    "\n",
    "### ***Absolute convergence implies convergence***\n",
    "### Convergence of a series means $\\displaystyle \\lim_{M\\to\\infty} \\left| S - \\sum_{n=1}^{M} a_n \\right| = 0 $ and the reason that absolute convergence of a series implies convergence is that\n",
    "## $$ \\left| \\sum_{n=M+1}^{N} a_n \\right| \\leq \\sum_{n=M+1}^{N} |a_n| \\to 0 \\quad \\text{as both}\\, M,N\\to\\infty $$\n",
    "\n",
    "### Because absolute convergence concerns the convergence of $\\displaystyle  \\sum_{n=1}^{\\infty} |a_n|$, we can apply all of the techniques we have learned to determine absolute convergence.\n",
    "\n",
    "### ***Example***\n",
    "\n",
    "### Consider the series\n",
    "## $$ \\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n^p} $$\n",
    "### Note that\n",
    "## $$ \\sum_{n=1}^{\\infty} \\left| \\frac{(-1)^n}{n^p} \\right| = \\sum_{n=1}^{\\infty} \\frac{1}{n^p} $$\n",
    "### Since $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{1}{n^p} $ converges for all $p>1$, $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n^p}$ is absolutely convergent for all $p>1$\n",
    "### Since $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{1}{n^p} $ diverges for all $p\\leq 1$, $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n^p}$ is not absolutely convergent for all $p\\leq 1$. We will see shortly that $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n^p} $ is conditionally convergent for all $p\\leq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb507806",
   "metadata": {},
   "source": [
    "## A note on the ratio test and root test\n",
    "\n",
    "### We can apply the ratio test and root test to series with negative terms by simply defining $L$ with absolute values.\n",
    "### For a series $\\displaystyle \\sum_{n=0}^{\\infty} a_n$, let\n",
    "## $$ L = \\left\\{ \\begin{array} {rcl} \\displaystyle \\lim_{n\\to\\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| & & \\text{for the ratio test} \\\\ \\displaystyle \\lim_{n\\to\\infty} |a_n|^{\\frac{1}{n}} & & \\text{for the root test} \\end{array} \\right. $$\n",
    "### Then for both tests, the conclusions are the same as before except stated in terms of absolute convergence:\n",
    "### 1. If $L<1$ then the series ***absolutely converges***;\n",
    "### 2. If $L>1$ then the series ***diverges***;\n",
    "### 3. If $L=1$ then there is ***no conclusion***\n",
    "### The additional information here is that when $L>1$ not only does $\\displaystyle \\sum_{n=0}^{\\infty} |a_n|$ diverge, the series without absolute signs $\\displaystyle \\sum_{n=0}^{\\infty} a_n $ also diverges. This is because when $L>1$, $\\displaystyle \\lim_{n\\to\\infty} a_n \\neq 0$ so by the divergence test, $\\displaystyle \\sum_{n=1}^{\\infty} a_n $ diverges.\n",
    "### When we talk about Taylor series, we will use the ratio test (or the root test) to find what is known as the radius of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ea433",
   "metadata": {},
   "source": [
    "## Alternating series\n",
    "\n",
    "### An ***alternating series*** is a series whose terms alternate in signs. That is, an alternating series takes the form\n",
    "## $$ \\pm \\sum_{n=1}^{\\infty} (-1)^n c_n\\quad\\text{where}\\,c_n>0 $$\n",
    "\n",
    "### ***The alternating series test***\n",
    "\n",
    "### There is a simple test for convergence of an alternating series.\n",
    "### If for all $n$ large enough,\n",
    "### - $\\displaystyle \\lim_{n\\to\\infty} c_n = 0 $,\n",
    "### - $c_n$ decreases as $n$ increases,\n",
    "### then $\\displaystyle \\pm \\sum_{n=1}^{\\infty} (-1)^n c_n\\,(c_n>0)$ converges.\n",
    "\n",
    "### ***Example: a conditionally convergent series***\n",
    "\n",
    "### The alternating series\n",
    "## $$ \\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1}}{n} = 1 -\\frac{1}{2}+\\frac{1}{3}-\\frac{1}{4}+\\cdots $$\n",
    "### is conditionally convergent (and not absolutely convergent).\n",
    "\n",
    "### To show this, first check for absolute convergence. The series is not absolutely convergent since\n",
    "## $$ \\sum_{n=1}^{\\infty} \\left| \\frac{(-1)^{n-1}}{n} \\right| = \\sum_{n=1}^{\\infty} \\frac{1}{n} $$\n",
    "### diverges (by integral comparison as discussed before).\n",
    "\n",
    "### Since the series is not absolutely convergent, we need to check for conditional convergence. The series satisfies both conditions of the alternating series test:\n",
    "### - $\\displaystyle \\lim_{n\\to\\infty} \\frac{1}{n} = 0 $,\n",
    "### - $\\displaystyle \\frac{1}{n}$ decreases as $n$ increases.\n",
    "\n",
    "### Hence, $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1}}{n}$ converges. Since the series converges but is not absolutely convergent, it is conditionally convergent. The same reasoning applies to $\\displaystyle \\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n^p}$ for $0<p<1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486d255",
   "metadata": {},
   "source": [
    "## General power series\n",
    "\n",
    "### For simplicity, we will start with power series centered at the point $x=0$. In the following text, the term \"power series\" is short for such a power series.\n",
    "### A ***power series*** is a series involving ***only non-negative*** powers of a variable $x$:\n",
    "## $$ f(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots = \\sum_{n=0}^{\\infty} a_n x^n $$\n",
    "### Note that the coefficients $a_i$ can be zero, and therefore a power series may have finitely many non-zero terms.\n",
    "### The ***radius of convergence*** $R$ of the power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n$, is a real number $0\\leq R < \\infty$ such that\n",
    "### - for $|x| < R$, the power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n $ converges (to a finite number);\n",
    "### - for $|x| > R$, the power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n $ diverges;\n",
    "### - for $|x| = R$, the power series may converge or diverge. But we will mostly ignore what happens at the end points of the interval of convergence.\n",
    "\n",
    "### ***Examples***:\n",
    "### - Geometric series: $\\displaystyle 1+x+x^2+x^3+\\cdots = \\sum_{n=0}^{\\infty} x^n$, radius of convergence is $1$.\n",
    "### - Polynomials $ \\displaystyle a_0 + a_1 x + a_2 x^2 + \\cdots + a_N x^N = \\sum_{n=0}^{N} a_n x^n$ are power series, because polynomials can be written as infinite series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n$ where $a_m = 0$ for all $m>N$. The radius of convergence for any polynomial is $\\infty$. In other words, the sum converges for all $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd0cb4d",
   "metadata": {},
   "source": [
    "## Finding the radius of convergence\n",
    "\n",
    "### Given a power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n $, the ratio test implies that the power series converges if\n",
    "## $$ \\lim_{n\\to\\infty} \\left|\\frac{a_{n+1}x^{n+1}}{a_n x^n}\\right| = \\lim_{n\\to\\infty} \\left|\\frac{a_{n+1}}{a_n}\\right| |x| < 1 $$\n",
    "### There are 3 possibilities:\n",
    "### 1. There is a finite number $R$ such that\n",
    "### - $\\displaystyle |x|<R\\implies \\lim_{n\\to\\infty} \\left|\\frac{a_{n+1}}{a_n} \\right||x| < 1 $, ***and***\n",
    "### - $\\displaystyle |x| > R \\implies \\lim_{n\\to\\infty} \\left|\\frac{a_{n+1}}{a_n} \\right||x| > 1 $.\n",
    "###     We say the radius of convergence is $R$.\n",
    "### 2. For all $\\displaystyle x\\quad \\lim_{n\\to\\infty} \\left|\\frac{a_{n+1}}{a_n} \\right||x| < 1$. We say the radius of convergence is $\\infty$. (All $x$ satisfy $|x|<\\infty$)\n",
    "### 3. $\\displaystyle \\lim_{n\\to\\infty} \\left|\\frac{a_{n+1}}{a_n} \\right||x| > 1 $ for all $x\\neq 0$. We say the radius of convergence is $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a6fd1",
   "metadata": {},
   "source": [
    "### ***Remark: Alternative method using ratio test***\n",
    "\n",
    "### (Note that in the method that follows, the $n+1$ term is in the denominator and the $n$ term is in the numerator, which is the opposite of the ratio test.)\n",
    "\n",
    "### Given a power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n $,\n",
    "\n",
    "### if $\\displaystyle \\lim_{n\\to\\infty} \\left| \\frac{a_n}{a_{n+1}} \\right| = R $ (where $R$ exists or is $\\infty$),\n",
    "### then the radius of convergence for the power series is $R$.\n",
    "\n",
    "### ***Example***\n",
    "### Consider $\\displaystyle \\sum_{n=0}^{\\infty} 2^n x^n$, then $\\displaystyle \\lim_{n\\to\\infty} \\left| \\frac{2^n}{2^{n+1}} \\right| = \\frac{1}{2} \\implies R = \\frac{1}{2}$\n",
    "\n",
    "### ***Root test for radius of convergence***\n",
    "\n",
    "### Given a power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n$, the root test implies that the power series converges if\n",
    "## $$ \\lim_{n\\to\\infty} \\sqrt[n]{|a_n x^n|} = \\lim_{n\\to\\infty} \\sqrt[n]{|a_n|} |x| < 1 $$\n",
    "### There are 3 possibilities:\n",
    "\n",
    "### 1. There is a finite number $R$ such that\n",
    "### - $\\displaystyle |x| < R \\implies \\lim_{n\\to\\infty} \\sqrt[n]{|a_n|}|x| < 1 $,\n",
    "### - $\\displaystyle |x| > R \\implies \\lim_{n\\to\\infty} \\sqrt[n]{|a_n|}|x| > 1 $.\n",
    "###    We say the radius of convergence is $R$.\n",
    "### 2. For all $\\displaystyle x\\quad \\lim_{n\\to\\infty} \\sqrt[n]{|a_n|}|x| < 1 $. We say the radius of convergence is $\\infty$. (All $x$ satisfy $|x|<\\infty$)\n",
    "### 3. $\\displaystyle \\lim_{n\\to\\infty} \\sqrt[n]{|a_n|}|x| > 1 $ for all $x\\neq 0$. We say the radius of convergence is $0$.\n",
    "\n",
    "### ***Example***\n",
    "### Consider $\\displaystyle \\sum_{n=0}^{\\infty} 2^n x^n $ then $\\displaystyle \\lim_{n\\to\\infty} \\sqrt[n]{|2^nx^n|} = 2|x| < 1 $ when $\\displaystyle |x|<\\frac{1}{2} $. This implies that the radius of convergence is $\\displaystyle R = \\frac{1}{2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a9dd9",
   "metadata": {},
   "source": [
    "## Properties of power series\n",
    "\n",
    "### Add, subtract, multiply, divide, differentiate, and integrate convergent power series as one does for polynomials. We will discuss multiplication and division at a later time.\n",
    "\n",
    "### Consider the power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n $, which converges for $|x|<A$.\n",
    "### - The derivative $\\displaystyle \\frac{d}{dx} \\sum_{n=0}^{\\infty} a_n x^n = \\sum_{n=1}^{\\infty} n a_n x^{n-1} $ also converges for $|x|<A$.\n",
    "### - The integral $\\displaystyle \\int \\left( \\sum_{n=0}^{\\infty} a_n x^n\\right) dx= c+\\sum_{n=0}^{\\infty} a_n \\frac{x^{n+1}}{n+1}$ also converges for $|x|<A$. Note that $c$ is the constant of integration.\n",
    "### Consider another power series $\\displaystyle \\sum_{n=0}^{\\infty} b_n x^n $, which converges for $|x|<B$.\n",
    "### - If $A\\neq B$, then $\\displaystyle \\left( \\sum_{n=0}^{\\infty} a_n x^n\\right) \\pm \\left(\\sum_{n=0}^{\\infty} b_n x^n\\right) = \\sum_{n=0}^{\\infty} (a_n \\pm b_n) x^n $ converges for $|x|<\\operatorname{min}(A,B)$.\n",
    "### - If $A=B$, then $\\displaystyle \\left(\\sum_{n=0}^{\\infty} a_n x^n\\right)\\pm\\left(\\sum_{n=0}^{\\infty} b_n x^n\\right) = \\sum_{n=0}^{\\infty} (a_n\\pm b_n) x^n $ has a radius of convergence which is at least $A$, but it could have a larger radius of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc4db5",
   "metadata": {},
   "source": [
    "## Taylor's formula\n",
    "\n",
    "### Recall that $n! = n(n-1)(n-2)\\cdots(3)(2)(1)$ for all integers $n\\geq 1$.\n",
    "### We define $0!=1$. This is a very valuable convention that simplifies many formulas.\n",
    "### The ***Taylor series*** of a function $f(x)$ is the following power series:\n",
    "## $$ \\frac{f(0)}{0!}x^0 + \\frac{f'(0)}{1!}x^1 + \\frac{f''(0)}{2!}x^2 + \\frac{f^{(3)}(0)}{3!}x^3 + \\cdots = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!}x^n $$\n",
    "### Just like any other power series, the Taylor series converges when $|x|<R$ where $R$ is the radius of convergence.\n",
    "\n",
    "### In this course, we only consider functions $f(x)$ that equal their Taylor series within the radius of convergence. This is a large class of functions that include many of the functions we regularly use. For all such functions:\n",
    "## $$ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!}x^n \\quad (\\text{for}\\,|x|<R) $$\n",
    "\n",
    "### ***Important examples***\n",
    "## - $\\displaystyle e^x = \\sum_{n=0}^{\\infty} \\frac{x^n}{n!} = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots $\n",
    "## - $\\displaystyle \\sin x = \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)!} = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots $\n",
    "## - $\\displaystyle \\sinh x = \\sum_{n=0}^{\\infty} \\frac{ x^{2n+1}}{(2n+1)!} = x + \\frac{x^3}{3!} + \\frac{x^5}{5!} +- \\frac{x^7}{7!} + \\cdots $\n",
    "## - $\\displaystyle \\cos x = \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n}}{(2n)!} = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\cdots $\n",
    "## - $\\displaystyle \\cosh x = \\sum_{n=0}^{\\infty} \\frac{ x^{2n}}{(2n)!} = 1 + \\frac{x^2}{2!} + \\frac{x^4}{4!} + \\frac{x^6}{6!} + \\cdots $\n",
    "### We will use Taylor's formula to derive the series for $\\sin x$ and $\\cos x$ on the next page.\n",
    "### Notice that the factorial appears in the denominator of all terms in all three power series above.\n",
    "### Using the Taylor series of $e^x$ we find a formula for the number $e$ as the rapidly converging series:\n",
    "## $$ e = \\sum_{n=0}^{\\infty} \\frac{1}{n!} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ecc5e",
   "metadata": {},
   "source": [
    "## Radius of convergence of Taylor series of sine\n",
    "\n",
    "### In the video, we find the Taylor series of  to be\n",
    "## $$ \\begin{array} {rcl} \\sin x & = & \\displaystyle x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots \\\\ \\, & = & \\displaystyle \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)!} \\quad (|x|<R) \\end{array} $$\n",
    "### We now use the ratio test to find the radius of convergence $R$:\n",
    "## $$ \\begin{array} {rcl} \\displaystyle \\lim_{n\\to\\infty} \\left| \\frac{(-1)^n x^{2(n+1)+1}}{(2(n+1)+1)!} \\right| \\left| \\frac{(2n+1)!}{(-1)^n x^{2n+1}} \\right| & = & \\displaystyle |x|^2 \\lim_{n\\to\\infty} \\frac{1}{(2n+2)(2n+3)} \\\\ \\, & = & \\displaystyle |x|^2 (0) = 0 \\quad \\text{for all}\\, x \\end{array} $$\n",
    "### Hence, the Taylor series is absolutely convergent for all $x$ and the radius of convergence is $R=\\infty$.\n",
    "### ***Remark***: If we are concerned with only convergence but not absolute convergence, we can use the alternating series test at each $x$ to show that the Taylor series for $\\sin x$ converges for all $x$.\n",
    "### Since for any $x$,\n",
    "### - $\\displaystyle \\lim_{n\\to\\infty} \\left| \\frac{(-1)^n x^{2n+1}}{(2n+1)!} \\right| = 0$\n",
    "### - $ \\displaystyle \\left| \\frac{(-1)^n x^{2n+1}}{(2n+1)!} \\right| $ decreases as $n$ increases,\n",
    "\n",
    "### the alternating series $\\displaystyle \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)!} $ converges for all $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3735c",
   "metadata": {},
   "source": [
    "## New series from old: multiplying series\n",
    "\n",
    "### So far, we have used Taylor's formula to obtain the following Taylor series:\n",
    "### - $\\displaystyle \\frac{1}{1-x} = \\sum_{n=0}^{\\infty} x^n $ for $|x|<1$.\n",
    "### - $\\displaystyle e^x = \\sum_{n=0}^{\\infty} \\frac{x^n}{n!} $\n",
    "### - $\\displaystyle \\sin x = \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)!} $\n",
    "### - $\\displaystyle \\cos x = \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n}}{(2n)!} $\n",
    "### We have also integrated the geometric series to obtain a power series for $\\ln(1-x)$:\n",
    "## $$ -\\ln(1-x) = \\sum_{n=1}^{\\infty} \\frac{x^n}{n} $$\n",
    "\n",
    "### We will now obtain more Taylor series from the ones above by performing addition, multiplication, differentiation, and integration on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573bd2f",
   "metadata": {},
   "source": [
    "## Multiplying two power series\n",
    "\n",
    "### We multiply two powers series using the same rule as when we multiply two polynomials.\n",
    "### Consider the power series $\\displaystyle \\sum_{n=0}^{\\infty} a_n x^n $, which converges for $|x|<A$, and the power series $\\displaystyle \\sum_{n=0}^{\\infty} b_n x^n$, which converges for $|x|<B$\n",
    "\n",
    "### - The product of the two power series converges for $|x| < \\operatorname{min}(A,B)$, but it could have a larger radius of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c2e09",
   "metadata": {},
   "source": [
    "### ***Example***\n",
    "### Consider the product of two exponential series:\n",
    "## $$ e^a e^b = \\left(1+a+\\frac{a^2}{2!}+\\frac{a^3}{3!}+\\frac{a^4}{4!}+\\cdots\\right)\\left(1+b+\\frac{b^2}{2!}+\\frac{b^3}{3!}+\\frac{b^4}{4!}+\\cdots\\right) $$\n",
    "### Is the product of these two series the same as the Taylor series of $e^{a+b}$?\n",
    "### We say that a term in this product has ***total degree 2*** if the power of $a$ plus the power of $b$ is 2.\n",
    "### If we look at the all total degree 2 terms in $a$ and $b$ in this product we get:\n",
    "## $$ \\begin{array} {rcl} \\text{Terms of total degree 2} & = & \\displaystyle \\frac{a^2}{2!} + ab + \\frac{b^2}{2!} \\\\ \\, & = & \\displaystyle \\frac{1}{2}(a^2+2ab+b^2) \\\\ \\, & = & \\displaystyle \\frac{(a+b)^2}{2!} \\end{array} $$\n",
    "### Can the terms of total degree $3$ be expressed in terms of $(a+b)^3$?\n",
    "### ***Answer***:\n",
    "## $$ \\begin{array} {rcl} \\text{Terms of total degree 3} & = & \\displaystyle \\frac{a^3}{3!} + \\frac{a^2}{2!}(b) + (a)\\frac{b^2}{2!}+\\frac{b^3}{3!} \\\\ \\, & = & \\displaystyle \\frac{1}{3!} (a^3+2a^2b+3ab^2+b^3) \\\\ \\, & = & \\displaystyle \\frac{(a+b)^3}{3!} \\end{array} $$\n",
    "### ***Remark***: The pattern above continues for all $n$. This is consistent with $e^ae^b = e^{a+b}$. To verify that this holds from the series formulas requires use of the Binomial Theorem:\n",
    "## $$ (a+b)^n = \\sum_{p=0}^{\\infty} \\frac{n!}{p!(n-p)!}a^pb^{n-p} $$\n",
    "### Here's the computation:\n",
    "## $$ \\begin{array} {rcl} \\text{Terms of total degree}\\,n & = & \\displaystyle \\sum_{p=0}^{\\infty} \\frac{a^p}{p!}\\frac{b^{n-p}}{(n-p)!} \\\\ \\, & = & \\displaystyle \\frac{1}{n!} \\sum_{p=0}^{\\infty} \\frac{n!}{p!(n-p)!}a^pb^{n-p} \\\\ \\, & = & \\displaystyle \\frac{(a+b)^n}{n!} \\end{array} $$\n",
    "### where in the last step we have used the Binomial Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486dae71",
   "metadata": {},
   "source": [
    "## Dividing power series\n",
    "\n",
    "### If\n",
    "## $$ F(x) = \\frac{G(x)}{H(x)} $$\n",
    "### where $F(x), G(x), H(x)$ are all power series, then we can find $F(x)$ by solving the following equation of power series degree by degree:\n",
    "## $$ F(x)H(x) = G(x) $$\n",
    "### The radius of convergence of $F(x)$ is more difficult to track, since $F(x)$ diverges whenever $H(x) = 0$ and $G(x) \\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf4fec",
   "metadata": {},
   "source": [
    "## Substitution\n",
    "\n",
    "### We can find the composition of two power series $f(g(x))$ by using similar rules as composition of polynomials. In this course, we will only substitute a polynomial $p(x)$ into a power series $f(x)$.\n",
    "\n",
    "### If the radius of convergence of the power series $f(x)$ is $R$ then the power series $f(p(x))$ converges whenever $|p(x)| < R$.\n",
    "\n",
    "### In particular, we can find a Taylor series for a function $f(x)$ at $x=0$ and then substitute in a polynomial of the form $p(x)=ax^n$ for  where $n\\geq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88ba5f",
   "metadata": {},
   "source": [
    "## Taylor series of the Error function\n",
    "\n",
    "### Recall the error function is defined by the following integral formula:\n",
    "## $$ \\operatorname{erf} (x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt $$\n",
    "### and cannot be expressed in terms of functions that we already know with algebraic operations such as addition and multiplication.\n",
    "\n",
    "### To obtain the Taylor series of the error function, we replace the integrand $e^{-t^2}$ with its Taylor series:\n",
    "## $$ \\begin{array} {rcl} \\operatorname{erf} & = & \\displaystyle \\frac{2}{\\sqrt{\\pi}}\\int_{0}^{x} e^{-t^2} dt \\\\ \\, & = &  \\displaystyle \\frac{2}{\\sqrt{\\pi}}\\int_{0}^{x} \\left( \\sum_{n=0}^{\\infty} \\frac{(-1)^n t^{2n}}{n!} \\right) dt \\\\ \\, & = & \\displaystyle \\frac{2}{\\sqrt{\\pi}} \\left( \\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)n!} \\right) \\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e1d599",
   "metadata": {},
   "source": [
    "## Taylor polynomials and remainder theorem\n",
    "\n",
    "### ***Taylor polynomials***\n",
    "\n",
    "### If the Taylor series of $f(x)$ is\n",
    "## $$ f(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots \\quad (\\text{for}\\,|x|<R) $$\n",
    "### then the polynomial\n",
    "## $$ P_n(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots + a_n x^n $$\n",
    "### is called the ***Taylor polynomial*** of degree $n$ of $f(x)$. In other words, the degree $n$ Taylor polynomial is the polynomial obtained by truncating the Taylor series to degree $n$.\n",
    "\n",
    "### The degree $1$ and degree $2$ Taylor polynomials for $f(x)$ are respectively the linear and quadratic approximations of $f(x)$ near $x=0$. The degree $n$ Taylor polynomial $P_n(x)$ is the best fit degree $n$ polynomial of $f(x)$ near $x=0$ in the sense that\n",
    "## $$ P_n^{(k)}(0) = f^{(k)}(0) \\quad \\text{for}\\, 0 < k \\leq n $$\n",
    "### In other words, at the point $x=0$, all the derivatives of the polynomial $P_n$ matches the respective derivatives of $f$.\n",
    "\n",
    "### Just as we use linear and quadratic approximations, we can use Taylor polynomials of any degree to approximate a function near a point. But how do we know how accurate the approximation is? And what degree of Taylor polynomial is needed to achieve a certain accuracy? The answer is in the ***Taylor Remainder Theorem*** below.\n",
    "\n",
    "## Taylor remainder theorem\n",
    "\n",
    "### Let $P_n(x) = a_0 + a_1 x + a_2 x^2 + \\cdots + a_n x^n$ be the degree $n$ Taylor polynomial of $f(x)$.\n",
    "### Then, if\n",
    "### - $f$ is $n+1$ times differentiable on the open interval $(0, x)$ i.e. $f', f'', \\ldots, f^{(n)}, f^{(n+1)}$ exist on the open interval $(0, x)$, and\n",
    "### - $f', f'', \\ldots,f^{(n)}$ are all continuous on the ***closed*** interval $[0, x]$,\n",
    "\n",
    "### then there is a number $c$ in $(0, x)$ such that\n",
    "## $$ R_n(x) = f(x) - P_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!} x^{n+1} \\quad (0<c<x) $$\n",
    "### This is the ***Taylor remainder theorem***, and $R_n(x)$ is called the ***remainder*** or ***error of approximation***.\n",
    "### The $n=0$ case is the Mean Value Theorem (MVT). As in the MVT, we do not know exactly where $c$ is. Nonetheless, the Taylor remainder theorem is useful in giving upper bounds on errors of approximation by Taylor polynomials.\n",
    "\n",
    "### ***Remark***: \n",
    "### The formula for $R_n$ is true even if $x$ is outside the radius of convergence $R$ of the Taylor series. If $|x|<R$ then in addition,\n",
    "## $$ \\lim_{n\\to\\infty} R_n(x) = 0 \\quad (|x|<R) $$\n",
    "### This means that within the radius of convergence, we can obtain an approximation of arbitrarily high accuracy by using a Taylor polynomial of high enough degree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf43c2",
   "metadata": {},
   "source": [
    "### ***Proof of the Taylor remainder theorem***\n",
    "### Given the hypothesis of the Taylor remainder theorem, we need to show there is a $c$ in the open interval $(0,x)$ such that\n",
    "## $$ R_n(x) = f(x) - P_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!} x^{n+1} \\quad (0<c<x) $$\n",
    "### In the proof below, we will use Rolle's theorem (a special case of the MVT in which the function takes the same value at the two end points), so let us first recall the statement of ***Rolle's Theorem***:\n",
    "\n",
    "### If $F$ is differentiable on $(0,x)$ and continuous on $[0,x]$ (as in the hypothesis of the MVT), and if $F(0) = F(x)$ then there is $c$ in $(0,x)$ such that $F'(c) = 0$.\n",
    "\n",
    "### Now, we proceed to prove the Remainder Theorem for any fixed degree $n$.\n",
    "### To begin, fix $x\\quad(x\\neq 0)$, and define\n",
    "## $$ a = \\frac{R_n(x)}{x^{n+1}} \\quad (\\text{such that}\\,R_n(x) = ax^{n+1}) $$\n",
    "### With this $a$, define a new function $F_n(t)$ with $0\\leq t\\leq x$:\n",
    "## $$ \\begin{array} {rcl} F_n(t) = R_n(t) - a t^{n+1} & = & \\left( f(t)-P_n(t) \\right) - a t^{n+1} \\\\ \\, & = & \\displaystyle f(t) - \\left( f(0) + f'(0)t + \\frac{f''(0)}{2}t^2 + \\cdots + \\frac{f^{(n)}(0)}{n!}t^n \\right) - at^{n+1} \\end{array} $$\n",
    "### Then, this new function has the following properties:\n",
    "## $$ \\begin{array} {rcl} F_n(x) & = & 0 \\\\ F_n(0) = F_n'(0) = F_n''(0)=\\cdots=F_n^{(n)}(0) & = & 0 \\end{array} $$\n",
    "### Moreover, $F_n$ is $n+1$ times differentiable on the interval $(0,x)$ with the first $n$ derivatives continuous on $[0,x]$ because the hypothesis of the theorem says that $f$ is $n+1$ times differentiable on $(0,x)$ with the first $n$ derivatives continuous on $[0,x]$, and $P_n+at^{n+1}$ is a polynomial.\n",
    "\n",
    "### Now, we find $a$ by iterated applications of Rolle's Theorem. Since $F_n$ is continuous on $[0,x]$ differentiable on $(0,x)$ and $F_n(x)=F_n(0)=0$ by Rolle's Theorem, there is $c_0$ with $0<c_0<x$ such that\n",
    "## $$ F_n'(c_0) = 0 \\quad (0<c_0<x) $$\n",
    "### But now since $F_n'(0) = 0$ as well, and $F_n'$ is continuous on $[0,c_0]$ and differentiable on $(,c_0)$ we can apply Rolle's Theorem to $F_n'$ on $[0,c_0]$ and obtain a number $c_1$ with $0<c_1<c_0<x$ such that\n",
    "## $$ F_n''(c_1) = 0 \\quad (0<c_1<c_0) $$\n",
    "### Again, $F_n''(0)=0$ and $F_n''$ satisfies the hypothesis of Rolle's Theorem, so we can apply Rolle's Theorem to $F_n''$ and obtain $c_2$ with $0<c_2<c_1<c_0<x$ such that\n",
    "## $$ F_n^{(3)}(c_2) = 0 \\quad (0<c_2<c_1) $$\n",
    "### We can continue to apply Rolle's Theorem to the higher derivatives of $F_n$ on shrinking intervals, with the last application to $F_n^{(n)}$. The end result is a number $c_n$ satisfying\n",
    "## $$ 0<c_n<c_{n-1}<\\cdots<c_2<c_1<c_0<x $$\n",
    "### such that\n",
    "## $$ F_n^{(n+1)}(c_n) = 0 \\quad (0<c_n<x) $$\n",
    "### This final equation gives an expression for $a$. Let $c=c_n$ We compute the derivative:\n",
    "## $$ \\begin{array} {rcl} \\displaystyle F_n^{(n+1)}(c) & = & \\displaystyle  \\left. \\frac{d^{n+1}}{(dt)^{n+1}} \\left( f(t) - \\left( f(0)+f'(0)t+\\frac{f''(0)}{2}t^2 + \\cdots + \\frac{f^{(n)}(0)}{n!}t^n \\right) -at^{n+1} \\right)\\right|_{t=c} \\\\ \\, & = & \\displaystyle f^{(n+1)}(c)-(n+1)!a = 0 \\end{array} $$\n",
    "### This implies $\\displaystyle a = \\frac{f^{(n+1)}(c)}{(n+1)!} $ for $0<c<x$.\n",
    "\n",
    "### We have shown that given any fixed degree $n$ and fixed $x\\quad(x\\neq 0)$, there is a number $c$ in $(0,x)$ such that\n",
    "## $$ R_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!}x^{n+1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271091f",
   "metadata": {},
   "source": [
    "## Worked example: Taylor approximation\n",
    "\n",
    "### We approximate $\\operatorname{erf}(1)$ by a Taylor polynomial of degree up to 2 and find an upper bound on the error of approximation.\n",
    "### Recall the Taylor series of $\\operatorname{erf}(1)$ is\n",
    "## $$ \\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\left(\\sum_{n=0}^{\\infty}\\frac{(-1)^n x^{2n+1}}{(2n+1)n!} \\right) $$\n",
    "### Since this series contains only odd power terms, the degree 1 and degree 2 Taylor polynomials are the same:\n",
    "## $$ P_2(x) = P_1(x) = \\frac{2}{\\sqrt{\\pi}}x $$\n",
    "### Hence, the approximation of $\\operatorname{erf}(1)$ by the Taylor polynomial of degree 2 is\n",
    "## $$ \\operatorname{erf}(1) \\approx P_2(1) = \\frac{2}{\\sqrt{\\pi}} $$\n",
    "### Now, we find an upper bound on the error of approximation $\\operatorname{erf}(1)-P_2(1)$. By the Taylor remainder theorem,\n",
    "## $$ \\begin{array} {rcl} \\operatorname{erf}(x)-P_2(x) & = & \\displaystyle\\frac{\\operatorname{erf}^{(3)}(c)}{3!}(x^3) \\quad \\text{for some }\\,0<c<x \\\\ \\implies \\operatorname{erf}(1)-P_2(1) & = & \\displaystyle \\frac{\\operatorname{erf}^{(3)}(c)}{3!}(1^3) \\quad \\text{for some }\\,0<c<1 \\end{array} $$\n",
    "### Now, we compute $\\operatorname{erf}^{(3)}(x)$:\n",
    "## $$ \\begin{array} {rcl} \\operatorname{erf}'(x) & = & \\displaystyle \\frac{2}{\\sqrt{\\pi}} e^{-x} \\quad (\\text{by FTC2}) \\\\ \\operatorname{erf}''(x) & = & \\displaystyle \\frac{2}{\\sqrt{\\pi}} (-2x)e^{-x^2} \\\\ \\operatorname{erf}^{(3)}(x) & = & \\displaystyle \\frac{2}{\\sqrt{\\pi}} \\left( -2e^{-x^2} + 4x^2e^{-x^2} \\right) \\\\ \\, & = & \\displaystyle \\frac{2}{\\sqrt{\\pi}} e^{-x^2} (2x^2-1) \\end{array} $$\n",
    "### Since both $|e^{-x^2}|<1$ and $|2x^2-1|<1$ for $0<x<1$ we conclude that\n",
    "## $$ |\\operatorname{erf}^{(3)}(c)| < \\frac{4}{\\sqrt{\\pi}}\\quad \\text{for all}\\,0<c<1 $$\n",
    "### In other words, $\\displaystyle\\frac{4}{\\sqrt{\\pi}}$ is an upper bound of $|\\operatorname{erf}^{(3)}|$ on the interval $(0,1)$. This gives an upper bound on the error of approximation:\n",
    "## $$ |\\operatorname{erf}(1)-P_2(1)| < \\left| \\frac{4/\\sqrt{\\pi}}{3!} \\right| = \\frac{1}{3}\\left(\\frac{2}{\\sqrt{\\pi}}\\right) $$\n",
    "### In other words, the error of the approximation of $\\operatorname{erf}(1)$ by $\\displaystyle P_2(1) = \\frac{2}{\\sqrt{\\pi}}$ is less than $\\displaystyle\\frac{1}{3}\\left(\\frac{2}{\\sqrt{\\pi}}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6de652",
   "metadata": {},
   "source": [
    "## Taylor series centered about other points\n",
    "\n",
    "### Let $g(t) = f(t+a)$. That is, $g$ is the translation of $f$ to the left by $a$.\n",
    "\n",
    "### Recall the Taylor series of $g(t)$ at $t=0$ is\n",
    "## $$ g(t) = \\sum_{n=0}^{\\infty} \\frac{g^{(n)}(0)}{n!} t^n \\quad (|t|<R) $$\n",
    "### Then\n",
    "## $$ \\begin{array} {rcl} f(t+a) = g(t) & = & \\displaystyle \\sum_{n=0}^{\\infty} \\frac{g^{(n)}(0)}{n!}t^n \\quad (|t|<R) \\\\ \\, & = & \\displaystyle \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!}t^n \\quad (|t|<R) \\end{array} $$\n",
    "### Now let $x=t+a$ In terms of $x$ the above formula becomes\n",
    "## $$ f(x) = \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(a)}{n!}(x-a)^n \\quad (|x-a|<R) $$\n",
    "### This is the Taylor series of $f(x)$ at $x=a$.\n",
    "\n",
    "### Note that the radius of convergence of the Taylor series of $f(x)$ at $x=a$ is the number $R$ such that $f(x)$ converges when $|x-a|<R$ and diverges when $|x-a|>R$.\n",
    "\n",
    "### If $a=0$, we get the formula for the Taylor series that we started with in this section. This special case of Taylor's formula gives us a power series often referred to as the ***Maclaurin series***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c97456",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
